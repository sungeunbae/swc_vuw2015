---
layout: page
title: From a Spreadsheet to a Database
subtitle: Storing Data in a Database
minutes: 10
---
> ## Learning Objectives {.objectives}
>
> * Write a short R program to create a single-table database by printing SQL statements.
> * Explain when and why to use this approach rather than connecting to the database programmatically.
> * Explain why inferences drawn from unnormalized data are always approximate.

We now have (key, author) pairs.
The next step is to put them in a relational database
so that we can start asking and answering questions.
Our starting point is the final script from the previous topic:


```{r}
for (i in 1:5) {
    key<-bibData[i,1]
    authors<-strsplit(as.character(bibData[i,4]),"; ")[[1]]
    if (length(authors)==0) {
      authors<-c('')
    }
    for (author in authors) {
        print(paste(key,author))
    }
}
```




whose output looks like this:

~~~ {.output}
[1] "8SW85SQM McClelland, James L"
[1] "85QV9X5F McClelland, J. L."
[1] "85QV9X5F McNaughton, B. L."
[1] "85QV9X5F O'Reilly, R. C."
[1] "Z4X6DT6N Ratcliff, R."
[1] "F5DGU3Q4 McCloskey, M."
[1] "F5DGU3Q4 Cohen, N. J."
[1] "PNGQMCP5 Buciluǎ, Cristian"
[1] "PNGQMCP5 Caruana, Rich"
[1] "PNGQMCP5 Niculescu-Mizil, Alexandru"
~~~

What we *want* is a series of SQL `insert` statements:

~~~ {.output}
insert into data values('8SW85SQM', 'McClelland, James L');
insert into data values('85QV9X5F', 'McClelland, J. L.');
insert into data values('85QV9X5F', 'McNaughton, B. L.');
~~~

so let's modify the program to print this instead:



```{r}
INSERT <- "insert into data values('%s','%s');"
for (i in 1:5) {
   key<-bibData[i,1]
   authors<-strsplit(as.character(bibData[i,4]),"; ")[[1]]
   if (length(authors)==0) {
       authors<-c('')
   }
   for (author in authors) {
       print(sprintf(INSERT,key,author))
   }
}
```
~~~ {.output}
[1] "insert into data values('8SW85SQM','McClelland, James L');"
[1] "insert into data values('85QV9X5F','McClelland, J. L.');"
[1] "insert into data values('85QV9X5F','McNaughton, B. L.');"
[1] "insert into data values('85QV9X5F','O'Reilly, R. C.');"
[1] "insert into data values('Z4X6DT6N','Ratcliff, R.');"
[1] "insert into data values('F5DGU3Q4','McCloskey, M.');"
[1] "insert into data values('F5DGU3Q4','Cohen, N. J.');"
[1] "insert into data values('PNGQMCP5','Buciluǎ, Cristian');"
[1] "insert into data values('PNGQMCP5','Caruana, Rich');"
[1] "insert into data values('PNGQMCP5','Niculescu-Mizil, Alexandru');"
~~~

The first change is the definition of `INSERT`,
which is the format string for our insertion statements.
The second change is that instead of printing the key and author directly,
we interpolate those values into `INSERT` using `sprintf`.

> ## Cutting Corners {.callout}
>
> R and other languages have libraries for interacting with databases,
> so why are we piping `insert` statements into SQLite instead?
> The answer is that it's a simple solution
> that uses all of the tools we have introduced so far.
> If we had to do anything more complicated with this data,
> we would almost certainly use `sqldf` and do things the right way.

This works,
but only if by "works" we mean
"runs to completion without an obvious error".
Upon closer inspection,
there are two problems:

1.  Nobody is actually creating a database table
    for us to insert things into.

2.  Authors names can contain single quotes.

3. Each output starts with [1] and the text is surrounded by double quotes \" \".

The first is easy to solve ---
we just add this at the start of our program:


```{r}
CREATE = 'create table data(key text not null, author text not null);'
```

and print it out before printing any of the `insert` statements.

The second problem is trickier:

if we interpolate a name like "O'Mear, Fiona" into `INSERT`,
the result will be:

```{r}
"insert into data values('RJS8QDC4', 'O'Mear, Fiona');"
```

which isn't legal R.
The fix there is simply to use double quotes around our strings instead of single quotes,
since people's names can't contain the former.

Once we make this change, our whole program is:


```{r}
INSERT <- "insert into data values(\"%s\",\"%s\");"
for (i in 1:5) {
   key<-bibData[i,1]
   authors<-strsplit(as.character(bibData[i,4]),"; ")[[1]]
   if (length(authors)==0) {
     authors<-c('')
   }
   for (author in authors) {
     cat(sprintf(INSERT,key,author),sep="\n")
   }
}
```
To use the double quotes inside `INSERT`, We used \\\". 

The heading [1] was removed by the use of `cat` instead of `print`.
The argument `sep="\n"` ensures each line is separated.

Let's run it:

~~~ {.output}
insert into data values("8SW85SQM","McClelland, James L");
insert into data values("85QV9X5F","McClelland, J. L.");
insert into data values("85QV9X5F","McNaughton, B. L.");
insert into data values("85QV9X5F","O'Reilly, R. C.");
insert into data values("Z4X6DT6N","Ratcliff, R.");
insert into data values("F5DGU3Q4","McCloskey, M.");
insert into data values("F5DGU3Q4","Cohen, N. J.");
insert into data values("PNGQMCP5","Buciluǎ, Cristian");
insert into data values("PNGQMCP5","Caruana, Rich");
insert into data values("PNGQMCP5","Niculescu-Mizil, Alexandru");
~~~

That looks pretty good.


Let's put everything together and save the following code as "convert-db.R". Note that the for loop now runs with all entries in bibData by `nrow(bibData)`.

```{r}
filename <- "/home/seb56/swc/swc_vuw2015/db/data/bibliography.csv"
bibData <- read.csv(file=filename, header=FALSE,sep=",")

CREATE = 'create table data(key text not null, author text not null);'
cat(CREATE,sep="\n")

INSERT <- "insert into data values(\"%s\",\"%s\");"
for (i in 1:nrows(bibData)) {
   key<-bibData[i,1]
   authors<-strsplit(as.character(bibData[i,4]),"; ")[[1]]
   if (length(authors)==0) {
     authors<-c('')
   }
   for (author in authors) {
     cat(sprintf(INSERT,key,author),sep="\n")
   }
}
```
and execute the following command.

~~~ {.input}
$ Rscript code/convert-db.R
~~~
This will output a SQL command that produces the `data` table followed by thosands of SQL insert commands. (Total of 6610 lines)

```{sql}
create table data(key text not null, author text not null);
insert into data values("8SW85SQM","McClelland, James L");
insert into data values("85QV9X5F","McClelland, J. L.");
insert into data values("85QV9X5F","McNaughton, B. L.");
insert into data values("85QV9X5F","O'Reilly, R. C.");
insert into data values("Z4X6DT6N","Ratcliff, R.");
insert into data values("F5DGU3Q4","McCloskey, M.");
insert into data values("F5DGU3Q4","Cohen, N. J.");
insert into data values("PNGQMCP5","Buciluǎ, Cristian");
...
insert into data values("UKMMCR7E","Osowski, Stanislaw");
insert into data values("UKMMCR7E","Hoai, Linh Tran");
insert into data values("UKMMCR7E","Markiewicz, Tomasz");

```
To create a database, let's use a pipe.
~~~ {.input}
$ Rscript code/convert-db.R | sqlite3 bibligraphy.db
~~~
 
This pipeline takes about four seconds to run on my laptop,
and creates a 205 kbyte file called `bibliography.db`.
Let's have a look at what that database contains:

~~~ {.input}
$ Rscript code/convert-db.R |sqlite3 bibliography.db
~~~

If this runs too slow, try the following instead.

~~~ {.input}
$ Rscript code/convert-db.R |sqlite3 -cmd "pragma synchronous=off" bibliography.db
~~~

> ## Creating database takes too long? {.callout}
> 
> The output of convert-db.R contains thousands of "insert" statement and by default, each insert statemt is treated as a transaction.
> SQLite might be doing only 60 transactions per second on a 7200RPM disk drive.
> The extra command "pragma synchronous=off" will cause SQLite to not wait on data to reach the disk surface, results in faster 
> completion. If you lose power in the middle of a transasaction, the database file might go corrupt (but it is very unliekly)


~~~ {.input}
$ sqlite3 bibliography.db
SQLite version 3.8.5 2014-08-15 22:37:57
Enter ".help" for usage hints.

sqlite> .schema
CREATE TABLE data(key text not null, author text not null);

sqlite> select * from data limit 10;
8SW85SQM|McClelland, James L
85QV9X5F|McClelland, J. L.
85QV9X5F|McNaughton, B. L.
85QV9X5F|O'Reilly, R. C.
Z4X6DT6N|Ratcliff, R.
F5DGU3Q4|McCloskey, M.
F5DGU3Q4|Cohen, N. J.
PNGQMCP5|Buciluǎ, Cristian
PNGQMCP5|Caruana, Rich
PNGQMCP5|Niculescu-Mizil, Alexandru
~~~

~~~{.sql}
sqlite> .mode column
sqlite> .header on
sqlite> select * from data limit 10;

key         author             
----------  -------------------
8SW85SQM    McClelland, James L
85QV9X5F    McClelland, J. L.  
85QV9X5F    McNaughton, B. L.  
85QV9X5F    O'Reilly, R. C.    
Z4X6DT6N    Ratcliff, R.       
F5DGU3Q4    McCloskey, M.      
F5DGU3Q4    Cohen, N. J.       
PNGQMCP5    Buciluǎ, Cristian 
PNGQMCP5    Caruana, Rich      
PNGQMCP5    Niculescu-Mizil, Al
~~~

That looks good,
so let's try asking some questions:

~~~ {.sql}
select author, count(*) from data group by author order by count(*) desc limit 10;
~~~
~~~ {.output}
author          count(*)  
--------------  ----------
Bengio, Yoshua  122       
Bengio, Y.      111       
Hinton, Geoffr  78        
LeCun, Yann     56        
Hinton, G. E.   45        
Salakhutdinov,  34        
LeCun, Y.       31        
Vincent, Pasca  29        
Jordan, M. I.   27        
Frasconi, P.    25   
~~~

The first thing we see is that our work has paid off:
we can now find out who the most prolific authors are with a single command.
The second thing we see is that we're not done yet:
"Bengio, Yoshua" and "Bengio, Y." are almost certainly the same person,
as are "LeCun, Yann" and "LeCun, Y.".
If we really want to know who has written the most papers,
we're going to have to reconcile different names for the same person.

> ## Denormalization is the Root of Much Evil {.callout}
>
> Data is **normalized** if it contains no redundancy.
> (The full definition has more conditions, but this is good enough for our purposes.)
> Our data is denormalized
> because it represents particular authors in several different ways.
> We can try to normalize the data using **heuristics** such as,
> "If the surname matches and the initialized form of the other parts of the name match, it's the same person."
> Errors will always creep in, however:
> in our case,
> we have no way of knowing whether "Albar, M." is Mohammd Albar or Michael Albar.
> Answers based on heuristically normalized data are therefore always approximations of reality.
> It is crucial in these cases that we record the heuristics we used
> and the transformations we made
> so that others (including our future selves)
> can check our work.

Instead of normalizing names,
let's see what other questions we can answer.
Who has co-authored papers with whom?

~~~ {.sql}
select a.author, b.author from data a join data b on a.key=b.key and a.author > b.author limit 10;
~~~
~~~ {.output}
author             author           
-----------------  -----------------
McNaughton, B. L.  McClelland, J. L.
O'Reilly, R. C.    McClelland, J. L.
O'Reilly, R. C.    McNaughton, B. L.
McCloskey, M.      Cohen, N. J.     
Caruana, Rich      Buciluǎ, Cristia
Niculescu-Mizil,   Buciluǎ, Cristia
Niculescu-Mizil,   Caruana, Rich    
Rigamonti, Robert  Fua, Pascal      
Rigamonti, Robert  Lepetit, Vincent 
Sironi, Amos       Fua, Pascal  
~~~

(We use `a.author > b.author` to ensure that
each distinct pair of authors only shows up once.)
What if we want to know how often different pairs of people have written together?

~~~ {.sql}
select a.author, b.author, count(*)
from data a join data b
on a.key=b.key and a.author > b.author
group by a.author, b.author
order by count(*) desc
limit 10;
~~~
~~~ {.output}
author           author          count(*)  
---------------  --------------  ----------
Vincent, Pascal  Bengio, Yoshua  27        
Roux, Nicolas L  Bengio, Yoshua  20        
Delalleau, Oliv  Bengio, Yoshua  19        
Bengio, Y.       Bengio, S.      18        
Larochelle, Hug  Bengio, Yoshua  15        
Roux, Nicolas L  Delalleau, Oli  15        
Vincent, P.      Bengio, Y.      15        
Chapados, N.     Bengio, Y.      14        
Gori, M.         Frasconi, P.    14        
Salakhutdinov,   Hinton, Geoffr  14  
~~~

Again,
we have a data normalization problem:
the pair "Vincent, Pascal" and "Bengio, Yoshua"
is almost certainly the same as the pair "Bengio, Y." and "Bengio, S.".
But that problem would be there
even if we were analyzing this data manually,
and putting it in a database has made asking new questions so easy
that we can do research we otherwise wouldn't have been able to tackle.

> ## Doing Things the Right Way {.challenge}
>
> Rewrite the R program to use the `sqldf` library to create the database
> instead of `cat` statements.

You will need to install sqldf package.

```{r}
install.packages("sqldf")
```
The revised code may look like this:
```{r}
filename <- "/home/seb56/swc/swc_vuw2015/db/data/bibliography.csv"
bibData <- read.csv(file=filename, header=FALSE,sep=",")
library(sqldf)

db<-dbConnect(SQLite(),dbname="Bibliography_sqldf.sqlite")

CREATE = 'create table data(key text not null, author text not null);'
dbSendQuery(conn=db, CREATE)

INSERT <- "insert into data values(\"%s\",\"%s\");"
for (i in 1:nrow(bibData)) {
  key<-bibData[i,1]
  authors<-strsplit(as.character(bibData[i,4]),"; ")[[1]]
  if (length(authors)==0) {
    authors<-c('')
  }
  for (author in authors) {
    cmd<-sprintf(INSERT,key,author)
    dbSendQuery(conn=db,cmd)
  }  
}

dbDisconnect(db)

```

> ## Distinct Pairs {.challenge}
>
> Explain why using `a.author > b.author` ensures that
> distinct pairs of authors only show up once.

> ## Normalization {.challenge}
>
> Write a function that takes two authors' names as input
> and returns `True` if they are probably the same person
> and `False` if they do not.
> Compare your function to your neighbor's:
> can you find a case where the two would disagree?

> ## Normalization (continuted) {.challenge}
>
> Use the function you wrote in the previous challenge
> to normalize authors' names.
> Compare your output to your neighbor's:
> have you produced exactly the same list of author names?
> If not,
> have you produced an equivalent list?
